{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zinara Vehicle License Compliance Prediction\n",
    "\n",
    "This notebook contains the machine learning development and experimentation for predicting vehicle license compliance in the Zinara system.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data Loading and Exploration](#data-loading)\n",
    "2. [Data Preprocessing](#preprocessing)\n",
    "3. [Feature Engineering](#feature-engineering)\n",
    "4. [Model Development](#model-development)\n",
    "5. [Model Evaluation](#evaluation)\n",
    "6. [Model Deployment](#deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, \n",
    "    roc_auc_score, confusion_matrix, classification_report,\n",
    "    roc_curve, precision_recall_curve\n",
    ")\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import shap\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Exploration <a name=\"data-loading\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '../data/raw/zinara_vehicle_licensing_data_2015_2024.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset loaded successfully! Shape: {df.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nBasic Statistics:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values:\")\n",
    "missing_data = df.isnull().sum()\n",
    "missing_percent = (missing_data / len(df)) * 100\n",
    "missing_df = pd.DataFrame({'Missing Values': missing_data, 'Percentage': missing_percent})\n",
    "display(missing_df[missing_df['Missing Values'] > 0])\n",
    "\n",
    "# Create target variable from License Status\n",
    "df['is_licensed'] = df['License Status'].map({'Compliant': True, 'Non-compliant': False, 'Expired': False})\n",
    "# Handle any unmapped values (set to False for safety)\n",
    "df['is_licensed'] = df['is_licensed'].fillna(False)\n",
    "\n",
    "# Check target distribution\n",
    "print(\"\\nTarget Distribution:\")\n",
    "target_dist = df['is_licensed'].value_counts()\n",
    "print(target_dist)\n",
    "print(f\"\\nClass Imbalance Ratio: {target_dist.min() / target_dist.max():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Vehicle type distribution\n",
    "df['Vehicle Type'].value_counts().plot(kind='bar', ax=axes[0,0])\n",
    "axes[0,0].set_title('Vehicle Type Distribution')\n",
    "axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Region distribution\n",
    "df['Region'].value_counts().plot(kind='bar', ax=axes[0,1])\n",
    "axes[0,1].set_title('Region Distribution')\n",
    "\n",
    "# Payment mode distribution\n",
    "df['Preferred Payment Mode'].value_counts().plot(kind='bar', ax=axes[0,2])\n",
    "axes[0,2].set_title('Payment Mode Distribution')\n",
    "\n",
    "# Days since renewal distribution\n",
    "df['Days Since Last Renewal'].hist(bins=50, ax=axes[1,0])\n",
    "axes[1,0].set_title('Days Since Last Renewal')\n",
    "\n",
    "# Total renewals distribution\n",
    "df['Number of Late Renewals in Last 3 Years'].hist(bins=30, ax=axes[1,1])\n",
    "axes[1,1].set_title('Total Renewals Distribution')\n",
    "\n",
    "# Target distribution\n",
    "df['is_licensed'].value_counts().plot(kind='pie', autopct='%1.1f%%', ax=axes[1,2])\n",
    "axes[1,2].set_title('License Status Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing <a name=\"preprocessing\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"Clean the dataset following best practices\"\"\"\n",
    "    print(\"Starting data cleaning process...\")\n",
    "    \n",
    "    # 1. Remove duplicates\n",
    "    initial_count = len(df)\n",
    "    df = df.drop_duplicates(subset=['Vehicle ID'])\n",
    "    print(f\"Removed {initial_count - len(df)} duplicate records\")\n",
    "    \n",
    "    # 2. Handle missing values intelligently\n",
    "    \n",
    "    # For payment modes - if payment is in-person/cash, online platform data should be null\n",
    "    online_payment_mask = df['Preferred Payment Mode'].isin(['online', 'mobile_money'])\n",
    "    \n",
    "    if 'online_platform_last_login' in df.columns:\n",
    "        df.loc[~online_payment_mask, 'online_platform_last_login'] = None\n",
    "        df.loc[online_payment_mask & df['online_platform_last_login'].isna(), 'online_platform_last_login'] = df['last_license_renewal']\n",
    "    \n",
    "    # 3. Handle date inconsistencies\n",
    "    date_columns = ['registration_date', 'last_license_renewal', 'license_expiry_date']\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    \n",
    "    # 4. Remove records with impossible dates\n",
    "    if 'registration_date' in df.columns:\n",
    "        df = df[df['registration_date'] <= pd.Timestamp.now()]\n",
    "    \n",
    "    # 5. Handle agent sync delays\n",
    "    if 'Agent Synchronization Lag' in df.columns and 'Preferred Payment Mode' in df.columns:\n",
    "        agent_payment_mask = df['Preferred Payment Mode'] == 'Agent'\n",
    "        df.loc[~agent_payment_mask, 'Agent Synchronization Lag'] = 0\n",
    "        \n",
    "        median_sync_delay = df.loc[agent_payment_mask, 'Agent Synchronization Lag'].median()\n",
    "        df.loc[agent_payment_mask & df['Agent Synchronization Lag'].isna(), 'Agent Synchronization Lag'] = median_sync_delay\n",
    "    \n",
    "    # 6. Clean vehicle types\n",
    "    if 'Vehicle Type' in df.columns:\n",
    "        df['Vehicle Type'] = df['Vehicle Type'].str.lower().str.strip()\n",
    "        type_mapping = {\n",
    "            'car': 'sedan',\n",
    "            'automobile': 'sedan',\n",
    "            'motorbike': 'motorcycle',\n",
    "            'bike': 'motorcycle',\n",
    "            'lorry': 'truck',\n",
    "            'pickup': 'truck'\n",
    "        }\n",
    "        df['Vehicle Type'] = df['Vehicle Type'].replace(type_mapping)\n",
    "    \n",
    "    # 7. Handle renewal counts\n",
    "    if 'Number of Late Renewals in Last 3 Years' in df.columns:\n",
    "        # Since we don't have total_renewals, we'll just ensure late renewals are reasonable\n",
    "        df['Number of Late Renewals in Last 3 Years'] = df['Number of Late Renewals in Last 3 Years'].clip(lower=0)\n",
    "    \n",
    "    # 8. Remove outliers using IQR method\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numerical_cols:\n",
    "        if col not in ['Vehicle ID', 'is_licensed']:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outlier_count = len(df[(df[col] < lower_bound) | (df[col] > upper_bound)])\n",
    "            if outlier_count > 0:\n",
    "                print(f\"Removing {outlier_count} outliers from {col}\")\n",
    "                df = df[(df[col] >= lower_bound) & (df[col] <= upper_bound)]\n",
    "    \n",
    "    print(f\"Data cleaning complete. Final dataset size: {len(df)}\")\n",
    "    return df\n",
    "\n",
    "# Clean the data\n",
    "df_clean = clean_data(df.copy())\n",
    "print(f\"\\nCleaned dataset shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering <a name=\"feature-engineering\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features for model training\"\"\"\n",
    "    print(\"Engineering features...\")\n",
    "    \n",
    "    # 1. Days since last renewal - already available as 'Days Since Last Renewal'\n",
    "    # No need to create this feature as it's already in the dataset\n",
    "    \n",
    "    # 2. Vehicle age - not available in dataset, skip\n",
    "    \n",
    "    # 3. Renewal frequency - not available in dataset, skip\n",
    "    \n",
    "    # 4. Late renewal rate - not available in dataset, skip\n",
    "    \n",
    "    # 5. Season of last renewal - Month and Quarter are already available in dataset\n",
    "    \n",
    "    # 6. Payment digitalization score\n",
    "    if 'Preferred Payment Mode' in df.columns:\n",
    "        digital_mapping = {\n",
    "            'Online': 1.0,\n",
    "            'Mobile Money': 0.8,\n",
    "            'Agent': 0.4,\n",
    "            'Cash': 0.0,\n",
    "            'Bank Transfer': 0.6\n",
    "        }\n",
    "        df['payment_digital_score'] = df['Preferred Payment Mode'].map(digital_mapping)\n",
    "    \n",
    "    # 7. Regional risk score\n",
    "    if 'Region' in df.columns:\n",
    "        region_risk = {\n",
    "            'Urban': 0.3,\n",
    "            'Peri-urban': 0.5,\n",
    "            'Rural': 0.7\n",
    "        }\n",
    "        df['region_risk_score'] = df['Region'].map(region_risk)\n",
    "    \n",
    "    # 8. Agent efficiency\n",
    "    if 'Agent Synchronization Lag' in df.columns:\n",
    "        max_delay = df['Agent Synchronization Lag'].max()\n",
    "        df['agent_efficiency'] = 1 - (df['Agent Synchronization Lag'] / (max_delay + 1))\n",
    "    \n",
    "    print(\"Feature engineering complete\")\n",
    "    return df\n",
    "\n",
    "# Engineer features\n",
    "df_featured = engineer_features(df_clean.copy())\n",
    "print(f\"\\nFeatured dataset shape: {df_featured.shape}\")\n",
    "print(\"\\nNew features added:\")\n",
    "new_features = set(df_featured.columns) - set(df_clean.columns)\n",
    "print(list(new_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_target(df, target_column='is_licensed'):\n",
    "    \"\"\"Prepare features and target for model training\"\"\"\n",
    "    \n",
    "    # Define feature columns\n",
    "    feature_cols = [\n",
    "        'Days Since Last Renewal', 'vehicle_age_years', 'Total Renewals',\n",
    "        'Number of Late Renewals in Last 3 Years', 'Average Renewal Lag Days', 'renewal_frequency',\n",
    "        'late_renewal_rate', 'payment_digital_score', 'region_risk_score',\n",
    "        'agent_efficiency', 'income_score', 'Month', 'Quarter'\n",
    "    ]\n",
    "    \n",
    "    # Add categorical features with encoding\n",
    "    categorical_features = []\n",
    "    \n",
    "    # Vehicle type encoding\n",
    "    if 'Vehicle Type' in df.columns:\n",
    "        vehicle_type_encoded = pd.get_dummies(df['Vehicle Type'], prefix='vehicle_type')\n",
    "        df = pd.concat([df, vehicle_type_encoded], axis=1)\n",
    "        categorical_features.extend(vehicle_type_encoded.columns.tolist())\n",
    "    \n",
    "    # Region encoding\n",
    "    if 'Region' in df.columns:\n",
    "        region_encoded = pd.get_dummies(df['Region'], prefix='region')\n",
    "        df = pd.concat([df, region_encoded], axis=1)\n",
    "        categorical_features.extend(region_encoded.columns.tolist())\n",
    "    \n",
    "    # Payment mode encoding\n",
    "    if 'Preferred Payment Mode' in df.columns:\n",
    "        payment_encoded = pd.get_dummies(df['Preferred Payment Mode'], prefix='payment')\n",
    "        df = pd.concat([df, payment_encoded], axis=1)\n",
    "        categorical_features.extend(payment_encoded.columns.tolist())\n",
    "    \n",
    "    # Income bracket encoding\n",
    "    if 'Income Bracket' in df.columns:\n",
    "        income_encoded = pd.get_dummies(df['Income Bracket'], prefix='income')\n",
    "        df = pd.concat([df, income_encoded], axis=1)\n",
    "        categorical_features.extend(income_encoded.columns.tolist())\n",
    "    \n",
    "    # Combine all features\n",
    "    all_features = feature_cols + categorical_features\n",
    "    \n",
    "    # Filter existing columns\n",
    "    available_features = [col for col in all_features if col in df.columns]\n",
    "    \n",
    "    # Prepare X and y\n",
    "    # Convert to numeric, coercing errors to NaN, then fill with 0\n",
    "    X = df[available_features].apply(pd.to_numeric, errors='coerce').fillna(0).astype(float)\n",
    "    y = ~df[target_column]  # Invert because we want to predict unlicensed\n",
    "    \n",
    "    print(f\"Prepared {len(available_features)} features for training\")\n",
    "    print(f\"Target distribution - Unlicensed: {y.sum()}, Licensed: {(~y).sum()}\")\n",
    "    \n",
    "    return X, y, available_features\n",
    "\n",
    "# Prepare features and target\n",
    "X, y, feature_names = prepare_features_target(df_featured.copy())\n",
    "print(f\"\\nFeature matrix shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Development <a name=\"model-development\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"\\nData split and scaling complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test, model_name):\n",
    "    \"\"\"Evaluate model performance\"\"\"\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = None\n",
    "    \n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred),\n",
    "    }\n",
    "    \n",
    "    if y_pred_proba is not None:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\n{model_name} Results:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(cm)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, class_weight='balanced'),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, class_weight='balanced', n_estimators=100),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, scale_pos_weight=(y_train == 0).sum() / (y_train == 1).sum())\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Training {name}...\")\n",
    "    \n",
    "    # Use scaled data for logistic regression, original for tree-based models\n",
    "    if name == 'Logistic Regression':\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        results[name] = evaluate_model(model, X_test_scaled, y_test, name)\n",
    "    else:\n",
    "        model.fit(X_train, y_train)\n",
    "        results[name] = evaluate_model(model, X_test, y_test, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nModel Comparison:\")\n",
    "display(results_df)\n",
    "\n",
    "# Plot comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "for i, metric in enumerate(metrics):\n",
    "    ax = axes[i//2, i%2]\n",
    "    results_df[metric].plot(kind='bar', ax=ax)\n",
    "    ax.set_title(f'Model Comparison - {metric.capitalize()}')\n",
    "    ax.set_ylabel(metric.capitalize())\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for the best model (XGBoost)\n",
    "print(\"Performing hyperparameter tuning for XGBoost...\")\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Calculate scale_pos_weight\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "# Initialize model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Perform grid search\n",
    "grid_search = GridSearchCV(\n",
    "    xgb_model, param_grid, cv=3, scoring='f1', n_jobs=-1, verbose=1\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"\\nBest parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best F1 score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Train best model\n",
    "best_model = grid_search.best_estimator_\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate best model\n",
    "best_metrics = evaluate_model(best_model, X_test, y_test, \"Tuned XGBoost\")\n",
    "\n",
    "# Feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': best_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Feature Importance:\")\n",
    "display(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation <a name=\"evaluation\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "y_pred_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall, precision, color='blue', lw=2)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()\n",
    "\n",
    "# Feature importance plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "feature_importance.head(15).plot(x='feature', y='importance', kind='barh', ax=plt.gca())\n",
    "plt.title('Top 15 Feature Importance')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis for model interpretability\n",
    "print(\"Performing SHAP analysis...\")\n",
    "\n",
    "# Create SHAP explainer for XGBoost (tree-based model)\n",
    "explainer = shap.TreeExplainer(best_model)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False)\n",
    "plt.title('SHAP Feature Importance Summary')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Waterfall plot for a single prediction\n",
    "sample_idx = 0\n",
    "shap.plots.waterfall(shap_values[sample_idx])\n",
    "plt.title(f'SHAP Waterfall Plot for Sample {sample_idx}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Deployment <a name=\"deployment\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model and scaler\n",
    "model_dir = '../data/models'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_dir, 'xgboost_model_v1.0.joblib')\n",
    "joblib.dump(best_model, model_path)\n",
    "\n",
    "# Save scaler\n",
    "scaler_path = os.path.join(model_dir, 'scaler_v1.0.joblib')\n",
    "joblib.dump(scaler, scaler_path)\n",
    "\n",
    "# Save feature names\n",
    "features_path = os.path.join(model_dir, 'features_v1.0.joblib')\n",
    "joblib.dump(feature_names, features_path)\n",
    "\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "print(f\"Scaler saved to: {scaler_path}\")\n",
    "print(f\"Features saved to: {features_path}\")\n",
    "\n",
    "# Save model metadata\n",
    "metadata = {\n",
    "    'model_type': 'XGBoost',\n",
    "    'version': '1.0',\n",
    "    'training_date': datetime.now().isoformat(),\n",
    "    'metrics': best_metrics,\n",
    "    'feature_importance': feature_importance.to_dict('records'),\n",
    "    'hyperparameters': grid_search.best_params_\n",
    "}\n",
    "\n",
    "metadata_path = os.path.join(model_dir, 'model_metadata_v1.0.json')\n",
    "import json\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2, default=str)\n",
    "\n",
    "print(f\"Metadata saved to: {metadata_path}\")\n",
    "print(\"\\nModel deployment files ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model loading and prediction\n",
    "print(\"Testing model loading and prediction...\")\n",
    "\n",
    "# Load model\n",
    "loaded_model = joblib.load(model_path)\n",
    "loaded_scaler = joblib.load(scaler_path)\n",
    "loaded_features = joblib.load(features_path)\n",
    "\n",
    "# Make prediction on a sample\n",
    "sample = X_test.iloc[0:1]\n",
    "sample_scaled = loaded_scaler.transform(sample)\n",
    "prediction = loaded_model.predict(sample_scaled)[0]\n",
    "probability = loaded_model.predict_proba(sample_scaled)[0][1]\n",
    "\n",
    "print(f\"Sample prediction: {prediction} (probability: {probability:.4f})\")\n",
    "print(f\"Actual value: {y_test.iloc[0]}\")\n",
    "print(\"\\nModel loading and prediction test successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has demonstrated the complete machine learning pipeline for predicting vehicle license compliance:\n",
    "\n",
    "1. **Data Loading & Exploration**: Loaded and analyzed the vehicle licensing dataset\n",
    "2. **Data Preprocessing**: Cleaned data, handled missing values, and removed outliers\n",
    "3. **Feature Engineering**: Created meaningful features from raw data\n",
    "4. **Model Development**: Trained and compared multiple ML models\n",
    "5. **Model Evaluation**: Evaluated performance using various metrics and visualizations\n",
    "6. **Model Deployment**: Saved the trained model for production use\n",
    "\n",
    "### Key Findings:\n",
    "- XGBoost performed best with F1 score of {best_metrics.get('f1_score', 'N/A'):.4f}\n",
    "- Top features include days since renewal, payment digitalization score, and agent efficiency\n",
    "- Model shows good discriminatory power with AUC of {best_metrics.get('roc_auc', 'N/A'):.4f}\n",
    "\n",
    "### Next Steps:\n",
    "1. Integrate the model into the Django application\n",
    "2. Set up automated model retraining pipeline\n",
    "3. Implement model monitoring and performance tracking\n",
    "4. Add A/B testing capabilities for model updates"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
